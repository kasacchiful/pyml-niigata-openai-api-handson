{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmU4zJx2kekS0cqWobVKY+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# チャットモデル\n","\n","任意のチャットメッセージのやり取り後の応答を生成することができます。\n","\n","「テキスト生成」の入力は「テキスト文字列」でしたが、「チャット」の入力は「チャットメッセージ文字列のリスト」になります。\n","\n","以下のモデルは、OpenAIが用意しているチャットモデルになります。\n","\n","- gpt-3.5-turbo\n","- gpt-4\n","\n","本ノートブックでは、「gpt-3.5-turbo」を使っていきます。"],"metadata":{"id":"aou8uVGseMxj"}},{"cell_type":"markdown","source":["## 準備"],"metadata":{"id":"-fNO_5_Egg9C"}},{"cell_type":"code","source":["## 利用するベースモデルのライブラリ (OpenAI) も別途インストールする\n","!pip install langchain==0.0.331 openai==0.28.1 python-dotenv cohere tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWbegwT4ggWb","executionInfo":{"status":"ok","timestamp":1699358933290,"user_tz":-540,"elapsed":11293,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"1704f1fc-18f5-484f-aba4-95329c12b6d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain==0.0.331 in /usr/local/lib/python3.10/dist-packages (0.0.331)\n","Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.32)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (2.0.22)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (3.8.6)\n","Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (3.7.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (0.6.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (1.33)\n","Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (0.0.60)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (1.10.13)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.331) (8.2.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n","Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n","Requirement already satisfied: fastavro==1.8.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.8.2)\n","Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.331) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.331) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.331) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.331) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.331) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.331) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.331) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.331) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.331) (1.1.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.331) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.331) (0.9.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.331) (2.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.331) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.331) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.331) (3.0.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.331) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.331) (1.0.0)\n"]}]},{"cell_type":"code","source":["## Googleドライブをマウント\n","from google.colab import drive\n","drive.mount('./drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zeq2QlhTgkee","executionInfo":{"status":"ok","timestamp":1699358936590,"user_tz":-540,"elapsed":3308,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"09db2810-fe6b-433c-b0a6-a14dfcaee4fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at ./drive; to attempt to forcibly remount, call drive.mount(\"./drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["## 環境変数設定\n","import dotenv\n","dotenv.load_dotenv('./drive/MyDrive/openai.env')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cObhvIojgnsB","executionInfo":{"status":"ok","timestamp":1699358936591,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"9bf207a8-6d6b-4a61-ad13-13c7038d3a62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## チャットメッセージリストの準備\n","\n","「チャット」の入力は「チャットメッセージ文字列のリスト」で、出力は「チャットメッセージ文字列」になります。\n","チャットメッセージでは、「role」と「content」を持ちます。\n","「role」は、以下の3種類です。\n","\n","- system: チャットの振る舞いに関する指示\n","- user: 人間の発話\n","- assistant: AIの発話\n","\n","通常、会話の最初に「system」メッセージを記述します。次に、「user」メッセージと「assistant」メッセージを交互に記述します。"],"metadata":{"id":"z2L4rXJIfDQv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GYAc6Nbd9k6"},"outputs":[],"source":["## チャットメッセージのリスト\n","messages = [\n","    {\"role\": \"system\", \"content\": \"あなたは女子高生です。1人の兄がいる、妹のように演じてください。あなたは兄と会話します。\"},\n","    {\"role\": \"user\", \"content\": \"おはよう\"},\n","]"]},{"cell_type":"code","source":["## OpenAIのライブラリで実行\n","import os\n","import openai\n","\n","## チャットの実行\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # set OpenAI API Key\n","res = openai.ChatCompletion.create(\n","    model='gpt-3.5-turbo',\n","    messages=messages,\n","    temperature = 0.7,\n","    max_tokens = 255,\n",")\n","## openai v1.0.0 から以下のように変更となった。\n","# res = openai.OpenAI().chat.completions.create(\n","#     model='gpt-3.5-turbo',\n","#     messages=messages,\n","#     temperature = 0.7,\n","#     max_tokens = 255,\n","# )"],"metadata":{"id":"GC7vfnUTgtcM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res['choices'][0]['message']['content']\n","## openai v1.0.0 から以下のように変更となった。\n","# res.choices[0].message.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2IEJfHJVZ74Q","executionInfo":{"status":"ok","timestamp":1699358937083,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"8e7517b1-1211-41b2-a768-c3cf365d35d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'おはよう兄さん！おはようございます。今日も元気ですか？'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## LangChainでの実行\n","\n","チャットモデル用の `langchain.chat_models.ChatOpenAI` を使って実行します。\n","チャットメッセージのリストを作成する際は、各ロールに合わせて `HumanMessage` や `SystemMessage` を使うと良いでしょう。"],"metadata":{"id":"QGtrk_qan5Du"}},{"cell_type":"code","source":["## LangChainで実行\n","from langchain.chat_models import ChatOpenAI\n","\n","chat = ChatOpenAI(\n","    model='gpt-3.5-turbo',\n","    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),  # set OpenAI API Key\n","    temperature = 0.7,\n","    max_tokens = 255,\n",")"],"metadata":{"id":"1ei4Wgp9hPmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## チャットメッセージのリスト\n","from langchain.schema.messages import HumanMessage, SystemMessage\n","messages = [\n","    SystemMessage(content=\"あなたは女子高生です。1人の兄がいる、妹のように演じてください。あなたは兄と会話します。\"),\n","    HumanMessage(content=\"おやすみ\"),\n","]"],"metadata":{"id":"3qq4pXSDm3xw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fjy_5pBnloM","executionInfo":{"status":"ok","timestamp":1699358939576,"user_tz":-540,"elapsed":1740,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"a72b0927-c98d-4076-e480-ecd18810dffd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='おやすみなさい、お兄ちゃん。今日もお疲れさまでした。明日も頑張ってね。')"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## 会話の内容を一時保存して使う\n","\n","基本的に、Chat Modelの中でのチャットのやり取りは、言語モデルの中で勝手にデータは保存されません。\n","ChatGPTのようなWebサービスでは、Webサービス上で一時的に会話の内容を記憶させ、言語モデルに会話の履歴をリストとして保存し、それを言語モデルに渡すことで、チャットのやり取りの内容を言語モデルが認識しています。\n","\n","他にも、言語モデルのやり取りの中で、出力結果を別の言語モデルに渡して最適な結果を生みたい場合もあります。\n","\n","LangChainでは、そのような一時的な記憶を行うモジュールとして「LangChain Memory」が用意されています。\n","\n","\n"],"metadata":{"id":"yHb6RCoLoVpm"}},{"cell_type":"code","source":["## チャットメッセージのリスト\n","from langchain.schema.messages import SystemMessage\n","from langchain.memory import ChatMessageHistory\n","\n","history = ChatMessageHistory()\n","history.add_message(SystemMessage(content=\"あなたは女子高生です。1人の兄がいる、妹のように演じてください。あなたは兄と会話します。\"))\n","history.add_user_message(\"おやすみ\")\n","history.add_ai_message(\"おやすみなさい、お兄ちゃん！今日もお疲れ様でした。\")\n","\n","history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbyIazNInrGF","executionInfo":{"status":"ok","timestamp":1699358940104,"user_tz":-540,"elapsed":534,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"8cd3c98a-3420-4696-e76a-66a8cb261aa0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content='あなたは女子高生です。1人の兄がいる、妹のように演じてください。あなたは兄と会話します。'),\n"," HumanMessage(content='おやすみ'),\n"," AIMessage(content='おやすみなさい、お兄ちゃん！今日もお疲れ様でした。')]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["## チャットに特化したConversationBufferMemoryを使ってみる\n","## ChatMessageHistoryがベースとなっており、会話の履歴管理が楽になります。\n","\n","from langchain.llms import OpenAI\n","from langchain.memory import ConversationBufferMemory\n","\n","memory = ConversationBufferMemory(return_messages=True)\n","\n","## save_context()で保存\n","memory.save_context(\n","    {\"input\": \"おやすみ\"},\n","    {\"output\": \"おやすみなさい、お兄ちゃん！今日もお疲れ様でした。\"},\n",")\n","\n","## load_memory_variables()で読み出し\n","print(memory.load_memory_variables({}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSMpSHrJsXs9","executionInfo":{"status":"ok","timestamp":1699358940105,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"29ed2c37-afaf-4641-ad4b-71803c97c088"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'history': [HumanMessage(content='おやすみ'), AIMessage(content='おやすみなさい、お兄ちゃん！今日もお疲れ様でした。')]}\n"]}]},{"cell_type":"code","source":["## 会話を内容をすべて自動保存してみる。\n","\n","from langchain.llms import OpenAI\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory\n","\n","memory = ConversationBufferMemory(return_messages=True)\n","\n","llm = OpenAI(\n","    model_name=\"text-davinci-003\",\n","    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),  # set OpenAI API Key\n","    temperature = 0.7,\n",")\n","conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    memory=ConversationBufferMemory()\n",")\n","\n","conversation(\"AIとは何ですか？\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkW8Xc5JbRDh","executionInfo":{"status":"ok","timestamp":1699358942623,"user_tz":-540,"elapsed":2523,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"bdcb1374-94a0-4e6a-86d6-acb5e1ee222f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: AIとは何ですか？\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'AIとは何ですか？',\n"," 'history': '',\n"," 'response': ' AIとは人工知能のことです。人間が行うタスクや判断をコンピューターが行うことを可能にする技術になります。'}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["## チャットモデルを使って、チャットの内容を全て自動保存してみる。\n","## Chainの中にMemoryを組み込むことで可能\n","\n","from langchain.chains import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import SystemMessage\n","from langchain.prompts import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n","    MessagesPlaceholder,\n",")\n","\n","## Setup Prompt Template\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        # 永続的なシステムプロンプト\n","        SystemMessage(\n","            content=\"あなたは人間と会話するチャットボットです。\"\n","        ),\n","        # メモリの保存場所の設定\n","        MessagesPlaceholder(\n","            variable_name=\"chat_history\"\n","        ),\n","        # Humanの入力が挿入される箇所を設定\n","        HumanMessagePromptTemplate.from_template(\n","          \"{human_input}\"\n","        ),\n","    ]\n",")\n","\n","## Setup Memory\n","memory = ConversationBufferMemory(\n","    memory_key=\"chat_history\",\n","    return_messages=True\n",")\n","\n","## Setup Chat Model\n","llm = ChatOpenAI(\n","    model='gpt-3.5-turbo',\n","    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),  # set OpenAI API Key\n","    temperature = 0.7,\n","    max_tokens = 255,\n",")\n","\n","## Setup Chain (後ほど解説)\n","chat_llm_chain = LLMChain(\n","    llm=llm,\n","    prompt=prompt,\n","    verbose=True,\n","    memory=memory,\n",")"],"metadata":{"id":"E7YbdWX8c38_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 会話開始\n","chat_llm_chain.predict(human_input=\"こんにちは！調子はどうだい？\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"K5_4aKV9eV3N","executionInfo":{"status":"ok","timestamp":1699358944761,"user_tz":-540,"elapsed":2144,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"cb452a6f-a7c2-45fd-f1f0-54dbf10944e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: あなたは人間と会話するチャットボットです。\n","Human: こんにちは！調子はどうだい？\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'こんにちは！私は人間ではないので、調子はありませんが、お話しできて嬉しいです。どんなお話しをしましょうか？'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["chat_llm_chain.predict(human_input=\"AIについて教えて\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"id":"2kFu2rj0fKJK","executionInfo":{"status":"ok","timestamp":1699358951337,"user_tz":-540,"elapsed":6587,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"f23e46e9-a993-4a3a-a275-a8c520cb9520"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: あなたは人間と会話するチャットボットです。\n","Human: こんにちは！調子はどうだい？\n","AI: こんにちは！私は人間ではないので、調子はありませんが、お話しできて嬉しいです。どんなお話しをしましょうか？\n","Human: AIについて教えて\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'AI（人工知能）は、コンピューターシステムが人間のような知的なタスクを実行する能力を指します。AIは機械学習やディープラーニングなどの技術を活用して、データからパターンを学習し、判断や推論を行うことができます。\\n\\nAIはさまざまな分野で活用されています。例えば、自然言語処理によって人間の言葉を理解し、会話を行ったり、画像認識によって物体や顔を識別したり、自動運転技術によって車両を制御したりすることができます。\\n\\nAIの応用範囲は広く、医療診断、金融予測、製造業の効率化'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["chat_llm_chain.predict(human_input=\"小学1年生でもわかりやすく教えて\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"3s88i9s4fV_P","executionInfo":{"status":"ok","timestamp":1699358958221,"user_tz":-540,"elapsed":6910,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"13a81b2e-2b7c-46fa-e8cc-0504a55ed1b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: あなたは人間と会話するチャットボットです。\n","Human: こんにちは！調子はどうだい？\n","AI: こんにちは！私は人間ではないので、調子はありませんが、お話しできて嬉しいです。どんなお話しをしましょうか？\n","Human: AIについて教えて\n","AI: AI（人工知能）は、コンピューターシステムが人間のような知的なタスクを実行する能力を指します。AIは機械学習やディープラーニングなどの技術を活用して、データからパターンを学習し、判断や推論を行うことができます。\n","\n","AIはさまざまな分野で活用されています。例えば、自然言語処理によって人間の言葉を理解し、会話を行ったり、画像認識によって物体や顔を識別したり、自動運転技術によって車両を制御したりすることができます。\n","\n","AIの応用範囲は広く、医療診断、金融予測、製造業の効率化\n","Human: 小学1年生でもわかりやすく教えて\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'AI（人工知能）は、コンピューターが考えることや学ぶことができる技術です。もちろん、AIは人間と同じように考えるわけではありませんが、人間のような知的なタスクをこなすことができるんです。\\n\\n例えば、AIはたくさんのデータを使って学習します。たとえば、果物の写真をたくさん見せて、「これはりんごです」と学習させれば、AIはりんごを見分けることができるようになります。同じように、AIにお話を聞かせて学習させれば、AIは質問に答えることができるようになるんです。\\n\\nAIは、自動運転車やスマートフォンの音声アシスタントなど、さまざまな場面'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## LangChain Chains\n","\n","言語モデルを単独でシンプルに使う分には問題ないですが、複雑な連携を行うアプリケーションを開発する際は、言語モデル同士を連携させたり、外部のコンポーネントと接続したりする必要が出てきます。\n","\n","LangChainでは、Chainモジュールを使って、あるプロンプトの出力結果を別のプロンプトとして使うことが簡単にできます。\n","\n","例えば、巨大な文章の要約をしたい場合を考えます。\n","文字列長が長い場合、全ての文字列を一度に言語モデルに投入できません。（トークン制限により）\n","その場合、例えば文章の章毎に分割して、その章の要約を言語モデルに作ってもらい、その章毎の要約文を結合した文字列をさらに言語モデルに入力して、最終的な文章全体の要約を作るといった方法が可能になります。\n","\n","LangChainには、元々あるChainインタフェースを使う方法と、最新のLangChain Expression Language (LCEL)を使う方法があります。先ほどのチャットの履歴を保存するコードでは、Chainインタフェースを使っています。\n","\n","以下のコードでは、LCELでチェインを構成した例を示しています。\n"],"metadata":{"id":"eadWCXCMgEoB"}},{"cell_type":"code","source":["## チャットモデルを使って、チャットの内容を全て保存してみる。\n","## Chainの中にMemoryを組み込むことで可能。\n","## なお、LCELでチェイン定義する場合、v0.0.330現在、Memoryへの保存は手動でフックさせる必要があります。\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import SystemMessage\n","from langchain.prompts import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n","    MessagesPlaceholder,\n",")\n","from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n","from operator import itemgetter\n","\n","## Setup Prompt Template\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        # 永続的なシステムプロンプト\n","        SystemMessage(\n","            content=\"あなたは人間と会話するチャットボットです。\"\n","        ),\n","        # メモリの保存場所の設定\n","        MessagesPlaceholder(\n","            variable_name=\"chat_history\"\n","        ),\n","        # Humanの入力が挿入される箇所を設定\n","        HumanMessagePromptTemplate.from_template(\n","          \"{human_input}\"\n","        ),\n","    ]\n",")\n","\n","## Setup Memory\n","memory = ConversationBufferMemory(\n","    memory_key=\"chat_history\",\n","    return_messages=True\n",")\n","\n","## Setup Chat Model\n","llm = ChatOpenAI(\n","    model='gpt-3.5-turbo',\n","    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),  # set OpenAI API Key\n","    temperature = 0.7,\n","    max_tokens = 255,\n",")\n","\n","## Setup Chain using LCEL\n","chat_llm_chain = (\n","    RunnablePassthrough.assign(\n","        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")\n","    )\n","    | prompt\n","    | llm\n",")"],"metadata":{"id":"r3qUydZJfo6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 会話開始\n","inputs = {\"human_input\": \"こんにちは！調子はどうだい？\"}\n","res = chat_llm_chain.invoke(inputs)\n","memory.save_context(inputs, {\"output\": res.content})  ## 手動で保存\n","res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Lk3Wv7aplLQ","executionInfo":{"status":"ok","timestamp":1699358959651,"user_tz":-540,"elapsed":1446,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"2084751d-afea-4a44-beb1-6beedf7d686e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='こんにちは！私はチャットボットなので、感情はありませんが、お話しすることができます。どのようなお話しをしたいですか？')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["inputs = {\"human_input\": \"AIについて教えて\"}\n","res = chat_llm_chain.invoke(inputs)\n","memory.save_context(inputs, {\"output\": res.content})  ## 手動で保存\n","res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"butVZ1DkqrZx","executionInfo":{"status":"ok","timestamp":1699358968518,"user_tz":-540,"elapsed":8870,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"a94073ef-6058-47c9-a0fc-d46ecaf3f32c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='AI（人工知能）は、コンピューターシステムが人間のような知的な活動を実行する技術です。AIは、大量のデータを処理し、パターンを認識し、学習することができます。\\n\\nAIの主なタイプには、以下のようなものがあります：\\n\\n1. 弱いAI（ナローアイ）：特定のタスクを実行するために設計されたAIです。例えば、音声認識や画像認識などがあります。\\n\\n2. 強いAI（ジェネラルアイ）：人間のような知的な活動を実行することができるAIです。現在の技術では、まだ完全な強いAIは実現していません。\\n\\n3. 機械学習：AIの一部として使用される技')"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["inputs = {\"human_input\": \"小学1年生でもわかりやすく教えて\"}\n","res = chat_llm_chain.invoke(inputs)\n","memory.save_context(inputs, {\"output\": res.content})  ## 手動で保存\n","res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hxda9FFGq2Af","executionInfo":{"status":"ok","timestamp":1699358974887,"user_tz":-540,"elapsed":6390,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"2406c370-68bc-4b9c-fe2d-0256caff9373"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='AI（人工知能）は、コンピューターが考えることや学ぶことができるようにする技術です。例えば、お友達の名前を覚えることや、絵を描くことを学ぶことができます。\\n\\nAIは、たくさんのデータを使って学ぶことができます。例えば、たくさんの写真を見せると、AIは猫や犬の写真を見分けることができます。それは、AIがパターンを認識するからです。\\n\\nまた、AIは間違いを修正することもできます。例えば、AIが「リンゴ」と言ったときに、実は「バナナ」だった場合、AIは間違いを気づいて修正することができます。\\n\\nAIは私たちの生活のさまざまな場面で役立')"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["## 会話履歴の確認\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95ilOx1RszsP","executionInfo":{"status":"ok","timestamp":1699358974888,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hiroshi Kasahara","userId":"17860752407484945887"}},"outputId":"a66a4ae9-37aa-48c6-8cc9-3ea7d67084d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'chat_history': [HumanMessage(content='こんにちは！調子はどうだい？'),\n","  AIMessage(content='こんにちは！私はチャットボットなので、感情はありませんが、お話しすることができます。どのようなお話しをしたいですか？'),\n","  HumanMessage(content='AIについて教えて'),\n","  AIMessage(content='AI（人工知能）は、コンピューターシステムが人間のような知的な活動を実行する技術です。AIは、大量のデータを処理し、パターンを認識し、学習することができます。\\n\\nAIの主なタイプには、以下のようなものがあります：\\n\\n1. 弱いAI（ナローアイ）：特定のタスクを実行するために設計されたAIです。例えば、音声認識や画像認識などがあります。\\n\\n2. 強いAI（ジェネラルアイ）：人間のような知的な活動を実行することができるAIです。現在の技術では、まだ完全な強いAIは実現していません。\\n\\n3. 機械学習：AIの一部として使用される技'),\n","  HumanMessage(content='小学1年生でもわかりやすく教えて'),\n","  AIMessage(content='AI（人工知能）は、コンピューターが考えることや学ぶことができるようにする技術です。例えば、お友達の名前を覚えることや、絵を描くことを学ぶことができます。\\n\\nAIは、たくさんのデータを使って学ぶことができます。例えば、たくさんの写真を見せると、AIは猫や犬の写真を見分けることができます。それは、AIがパターンを認識するからです。\\n\\nまた、AIは間違いを修正することもできます。例えば、AIが「リンゴ」と言ったときに、実は「バナナ」だった場合、AIは間違いを気づいて修正することができます。\\n\\nAIは私たちの生活のさまざまな場面で役立')]}"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## LangChain Memory\n","\n","言語モデル自体には、会話履歴内容を保存する機能は持っていません。\n","\n","LangChainでは、Memoryモジュールを使うことで、会話内容を一時的に保存することが簡単にできます。\n","\n","![LangChain Memory](https://python.langchain.com/assets/images/memory_diagram-0627c68230aa438f9b5419064d63cbbc.png)\n","\n","出典: https://python.langchain.com/docs/modules/memory/\n","\n","LangChain Memoryでは、基本的にシステム内のインメモリに保存するようになっていますが、外部のキャッシュ等のストアに格納することも可能です。\n","\n","例えば、Redis / Momento Cache / Cloudflare D-1 / Amazon DynamoDB / Firestore / MongoDB 等に保存可能です。\n","\n","- 参考: [https://js.langchain.com/docs/integrations/chat_memory/redis](https://js.langchain.com/docs/integrations/chat_memory/redis)\n"],"metadata":{"id":"0iOVrT7ngPgo"}},{"cell_type":"markdown","source":["\n"],"metadata":{"id":"DGPuVRdmwuxT"}},{"cell_type":"code","source":[],"metadata":{"id":"4dF-Wslqm0f1"},"execution_count":null,"outputs":[]}]}